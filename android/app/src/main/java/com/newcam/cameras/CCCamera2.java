package com.newcam.cameras;

import android.annotation.TargetApi;
import android.app.AlertDialog;
import android.content.Context;
import android.content.DialogInterface;
import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.ImageFormat;
import android.graphics.Matrix;
import android.graphics.PointF;
import android.graphics.Rect;
import android.hardware.camera2.CameraAccessException;
import android.hardware.camera2.CameraCaptureSession;
import android.hardware.camera2.CameraCharacteristics;
import android.hardware.camera2.CameraDevice;
import android.hardware.camera2.CameraManager;
import android.hardware.camera2.CameraMetadata;
import android.hardware.camera2.CaptureFailure;
import android.hardware.camera2.CaptureRequest;
import android.hardware.camera2.CaptureResult;
import android.hardware.camera2.TotalCaptureResult;
import android.hardware.camera2.params.MeteringRectangle;
import android.hardware.camera2.params.StreamConfigurationMap;
import android.media.AudioManager;
import android.media.Image;
import android.media.ImageReader;
import android.media.MediaActionSound;
import android.os.Handler;
import android.os.HandlerThread;
import android.support.annotation.NonNull;
import android.util.Log;
import android.util.Size;
import android.util.SparseIntArray;
import android.util.TypedValue;
import android.view.MotionEvent;
import android.view.Surface;
import android.view.SurfaceHolder;

import com.newcam.CCCameraView;
import com.newcam.enums.CameraMode;
import com.newcam.enums.FlashMode;
import com.newcam.enums.PhotoOrigin;
import com.newcam.R;
import com.newcam.enums.ResolutionMode;
import com.newcam.utils.ExifUtils;
import com.newcam.utils.PhotoUtils;
import com.notagilx.companycam.util.LogUtil;
import com.notagilx.companycam.util.views.CameraPreview;

import java.io.BufferedOutputStream;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.IOException;
import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.concurrent.Semaphore;
import java.util.concurrent.TimeUnit;

import static android.content.Context.CAMERA_SERVICE;

/**
 * Created by mattboyd on 2/5/17.
 */

@TargetApi(21)
public class CCCamera2 extends CCCamera implements SurfaceHolder.Callback {

    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
    // Much of the camera-related content of this class is taken from the Google example project Camera2Basic on github.
    // https://github.com/googlesamples/android-Camera2Basic
    //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

    private static String TAG = CCCamera2.class.getSimpleName();

    // The ORIENTATIONS array is used to assign numerical values to the Surface.ROTATION constants when handling the device and camera sensor
    // orientations.
    private static final SparseIntArray ORIENTATIONS = new SparseIntArray();
    static {
        ORIENTATIONS.append(Surface.ROTATION_0, 90);
        ORIENTATIONS.append(Surface.ROTATION_90, 0);
        ORIENTATIONS.append(Surface.ROTATION_180, 270);
        ORIENTATIONS.append(Surface.ROTATION_270, 180);
    }

    // The following constants are used to track the state of the camera

    //Camera state: Showing camera preview.
    private static final int STATE_PREVIEW = 0;

    // Camera state: Waiting for the focus to be locked.
    private static final int STATE_WAITING_LOCK = 1;

    // Camera state: Waiting for the exposure to be precapture state.
    private static final int STATE_WAITING_PRECAPTURE = 2;

    // Camera state: Waiting for the exposure state to be something other than precapture.
    private static final int STATE_WAITING_NON_PRECAPTURE = 3;

    // Camera state: Picture was taken.
    private static final int STATE_PICTURE_TAKEN = 4;

    // mState is the current state of camera state for taking pictures.
    private int mState = STATE_PREVIEW;

    // Define the maximum preview width and height guaranteed by the Camera2 API.
    private static final int MAX_PREVIEW_WIDTH = 4000;
    private static final int MAX_PREVIEW_HEIGHT = 3000;

    // The mStateCallback handles the program flow when the camera state changes.
    private CameraDevice.StateCallback mStateCallback;

    // The mCaptureCallback handles the program flow during a photo capture.
    private CameraCaptureSession.CaptureCallback mCaptureCallback;

    // The mPreviewRequestBuilder is used to create the camera preview.
    private CaptureRequest.Builder mPreviewRequestBuilder;

    // The mPreviewRequest is generated by the mPreviewRequestBuilder and used to create the camera preview.
    private CaptureRequest mPreviewRequest;

    // The mCaptureSession is used to display the camera preview and to capture the photo.
    private CameraCaptureSession mCaptureSession;

    // The mCameraOpenCloseLock Semaphore is used to prevent the app from exiting before closing the camera.
    private Semaphore mCameraOpenCloseLock = new Semaphore(1);

    // mCamera is a reference to the camera currently being used
    private CameraDevice mCamera;
    private String mCameraId;

    // mCameraType is a reference to the camera type (rear- or forward-facing) currently being used
    private int mCameraType = CameraCharacteristics.LENS_FACING_BACK;

    private Size mPreviewSize;
    private Surface mJpegCaptureSurface, mPreviewSurface;
    private CameraCharacteristics mCharacteristics;

    // The ImageReader object is used to read the camera stream output
    private ImageReader mJPEGReader;
    private final int HIGH_QUALITY = 80;

    // The mManualAutoFocus flag indicates whether or not the user initialized tap-to-autofocus
    private boolean mManualAutoFocus = false;

    // The mMeteringRect is the metering rectangle to be used for auto focus and auto exposure based on the user's touch point
    private MeteringRectangle[] mMeteringRect = { new MeteringRectangle(0, 0, 0, 0, 0) };

    // The mBackgroundThread is an additional thread for running tasks that shouldn't block the UI.
    private HandlerThread mBackgroundThread;

    // The mBackgroundHandler handles tasks running in the background.
    private Handler mBackgroundHandler;

    // The mCameraClosedCallback is a string that describes whether or not a specific callback should execute after the camera is successfully closed
    private String mCameraClosedCallback = "none";

    public CCCamera2(Context context, CCCameraView cameraView) {
        super(context, cameraView);

        init();
    }

    public void init() {

        // Initialize the mStateCallback for the camera
        mStateCallback = new CameraDevice.StateCallback() {

            @Override
            public void onOpened(@NonNull CameraDevice cameraDevice) {

                System.out.println("mStateCallback onOpened called");

                // This method is called when the camera is opened.  We start camera preview here.
                mCameraOpenCloseLock.release();
                mCamera = cameraDevice;

                // Initialize the camera preview
                initPreview();
            }

            @Override
            public void onDisconnected(@NonNull CameraDevice cameraDevice) {

                System.out.println("mStateCallback onDisconnected called");

                mCameraOpenCloseLock.release();
                cameraDevice.close();
                mCamera = null;
            }

            @Override
            public void onClosed(@NonNull CameraDevice cameraDevice) {

                System.out.println("mStateCallback onClosed called");

                mCameraOpenCloseLock.release();

                // If there's a callback to execute after the camera is closed, then execute it and reset the mCameraClosedCallback string
                if (mCameraClosedCallback != null) {
                    if (mCameraClosedCallback.equals("openCamera")) {
                        mCameraClosedCallback = "";
                        openCamera(mPreview.getHolder());
                    }
                }
            }

            @Override
            public void onError(@NonNull CameraDevice cameraDevice, int error) {

                String errorMsg = "Unknown camera error";
                switch (error) {
                case CameraDevice.StateCallback.ERROR_CAMERA_IN_USE:
                    errorMsg = "Camera is already in use.";
                    break;
                case CameraDevice.StateCallback.ERROR_MAX_CAMERAS_IN_USE:
                    errorMsg = "Max number of cameras are open, close previous cameras first.";
                    break;
                case CameraDevice.StateCallback.ERROR_CAMERA_DISABLED:
                    errorMsg = "Camera is disabled, e.g. due to device policies.";
                    break;
                case CameraDevice.StateCallback.ERROR_CAMERA_DEVICE:
                    errorMsg = "Camera device has encountered a fatal error, please try again.";
                    break;
                case CameraDevice.StateCallback.ERROR_CAMERA_SERVICE:
                    errorMsg = "Camera service has encountered a fatal error, please try again.";
                    break;
                }
                System.out.println("mStateCallback onError called (" + errorMsg + ")");

                mCameraOpenCloseLock.release();
                cameraDevice.close();
                mCamera = null;

                mCameraView.finishWithError(errorMsg);
            }
        };

        // Initialize the mCaptureCallback
        mCaptureCallback = new CameraCaptureSession.CaptureCallback() {

            // The lock states are used to track the real states of the AF and AE routines and ignore transient null or invalid states
            private int numConsecutiveAFLockStates = 0;
            private int numConsecutiveAFInactiveStates = 0;
            private int numConsecutiveAFScanStates = 0;

            // Check the current camera state whenever the capture has progressed or completed to determine the correct behavior
            private void process(CaptureResult result) {
                switch (mState) {
                case STATE_PREVIEW: {

                    // Simply make sure the that AF and AE state tracking variables are set to 0 before any auto focus event starts
                    numConsecutiveAFLockStates = 0;
                    numConsecutiveAFInactiveStates = 0;
                    numConsecutiveAFScanStates = 0;

                    break;
                }
                case STATE_WAITING_LOCK: {

                    System.out.println("mCaptureCallback: STATE_WAITING_LOCK");

                    // Check the auto focus state and auto exposure state
                    Integer afState = result.get(CaptureResult.CONTROL_AF_STATE);
                    Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);

                    if (afState != null) {
                        System.out.println(
                                "auto focus state was " + getAFStateString(afState) + " in STATE_WAITING_LOCK");
                    }
                    if (aeState != null) {
                        System.out.println(
                                "auto exposure state was " + getAEStateString(aeState) + " in STATE_WAITING_LOCK");
                    }

                    // If the auto focus state is null or INACTIVE, then the auto focus completion handler can be called.
                    if (afState == null || afState == 0) {

                        if (afState == null) {
                            System.out.println("auto focus state was null in STATE_WAITING_LOCK");
                        } else if (afState == 0) {
                            System.out.println("auto focus state was zero in STATE_WAITING_LOCK");
                        }

                        // Reset the numConsecutiveAFLockStates and numConsecutiveAFScanState since the auto focus isn't locked or scanning
                        numConsecutiveAFLockStates = 0;
                        numConsecutiveAFScanStates = 0;

                        // Increment the numConsecutiveAFInactiveStates
                        numConsecutiveAFInactiveStates++;

                        // If there have been at least three consecutive callbacks where the auto focus state is null or INACTIVE, then the
                        // onAutoFocusComplete function can be called.  If there haven't been at least three consecutive callbacks, then this
                        // auto focus state may be transient.
                        if (numConsecutiveAFInactiveStates >= 3) {
                            onAutoFocusComplete();
                            return;
                        }
                    }

                    // If the auto focus state is in a scan mode, then monitor the number of consecutive callbacks.  Some devices seems to
                    // get stuck in scan modes and never finish
                    else if (CaptureResult.CONTROL_AF_STATE_ACTIVE_SCAN == afState
                            || CaptureResult.CONTROL_AF_STATE_PASSIVE_SCAN == afState) {

                        // Reset the numConsecutiveAFLockState and numConsecutiveAFInactiveState since the auto focus is scanning
                        numConsecutiveAFLockStates = 0;
                        numConsecutiveAFInactiveStates = 0;

                        // Increment the numConsecutiveAFScanStates
                        numConsecutiveAFScanStates++;

                        // If there have been at least 30 consecutive scan states, then the device may not ever find focus, so call the
                        // onAutoFocusComplete function
                        if (numConsecutiveAFScanStates >= 30) {
                            onAutoFocusComplete();
                            return;
                        }

                    }

                    // If the auto focus is locked, then the photo can be captured if the auto exposure has finished
                    else if (CaptureResult.CONTROL_AF_STATE_FOCUSED_LOCKED == afState
                            || CaptureResult.CONTROL_AF_STATE_NOT_FOCUSED_LOCKED == afState) {

                        // Reset the numConsecutiveAFInactiveStates since the auto focus is locked
                        numConsecutiveAFInactiveStates = 0;
                        numConsecutiveAFScanStates = 0;

                        // Increment the numConsecutiveAFLockStates
                        numConsecutiveAFLockStates++;

                        // If there have been at least three consecutive callbacks where the auto focus is locked, then the onAutoFocusComplete
                        // function can be called for normal Camera mode.  If there haven't been at least three consecutive callbacks, then this
                        // auto focus state may be transient.
                        if (numConsecutiveAFLockStates >= 3 && (mCameraMode != CameraMode.FASTCAM)
                                && (mFlashMode != FlashMode.AUTO)) {
                            onAutoFocusComplete();
                            return;
                        }

                        // Check the CONTROL_AE_STATE to see if the auto exposure has finished.  It can be null on some devices.
                        if (aeState == null || aeState == CaptureResult.CONTROL_AE_STATE_CONVERGED) {

                            System.out.println(
                                    "auto focus state was locked and ae state was converged in STATE_WAITING_LOCK");

                            // If there have been at least three consecutive callbacks where the auto focus state is locked, then the
                            // onAutoFocusComplete function can be called.  If there haven't been at least three consecutive callbacks, then this
                            // auto focus state may be transient.
                            if (numConsecutiveAFLockStates >= 3) {
                                onAutoFocusComplete();
                                return;
                            }
                        }

                        // If the auto exposure hasn't started, then run the precapture sequence.
                        else {
                            runPrecaptureSequence();
                        }
                    } else {

                        // If the auto focus and auto exposure fall into any other category, reset all the lock states
                        numConsecutiveAFLockStates = 0;
                        numConsecutiveAFInactiveStates = 0;
                        numConsecutiveAFScanStates = 0;
                    }
                    break;
                }
                case STATE_WAITING_PRECAPTURE: {

                    System.out.println("mCaptureCallback: STATE_WAITING_PRECAPTURE");

                    // Check the CONTROL_AE_STATE to see if the auto exposure has finished.  It can be null on some devices.
                    Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState == null || aeState == CaptureResult.CONTROL_AE_STATE_PRECAPTURE
                            || aeState == CaptureRequest.CONTROL_AE_STATE_FLASH_REQUIRED) {

                        // Update the camera state to reflect that the precapture sequence is complete
                        mState = STATE_WAITING_NON_PRECAPTURE;
                    }
                    break;
                }
                case STATE_WAITING_NON_PRECAPTURE: {

                    System.out.println("mCaptureCallback: STATE_WAITING_NON_PRECAPTURE");

                    // Check the CONTROL_AE_STATE to see if the auto exposure has finished.  It can be null on some devices.
                    Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                    if (aeState == null || aeState != CaptureResult.CONTROL_AE_STATE_PRECAPTURE) {

                        // Call onAutoFocusComplete to capture the still photo
                        onAutoFocusComplete();
                    }
                    break;
                }
                default:
                    break;
                }
            }

            // This method either initiates the still picture capture or unlocks the focus after autofocus is complete based on whether the
            // autofocus was part of a photo capture sequence or a result of tap-to-autofocus.
            private void onAutoFocusComplete() {

                // After auto focus is complete, reset the state counters
                numConsecutiveAFLockStates = 0;
                numConsecutiveAFInactiveStates = 0;

                if (mManualAutoFocus) {

                    // If this was a tap-to-autofocus event, then reset the mManualAutoFocus and unlock the focus again
                    mManualAutoFocus = false;
                    unlockFocus();
                } else {

                    // If this wasn't a tap-to-autofocus event, then capture the photo
                    mState = STATE_PICTURE_TAKEN;
                    captureStillPicture();
                }
            }

            @Override
            public void onCaptureProgressed(@NonNull CameraCaptureSession session, @NonNull CaptureRequest request,
                    @NonNull CaptureResult partialResult) {
                //System.out.println("onCaptureProgressed for tag = " + request.getTag());

                //process(partialResult);
            }

            @Override
            public void onCaptureCompleted(@NonNull CameraCaptureSession session, @NonNull CaptureRequest request,
                    @NonNull TotalCaptureResult result) {

                //System.out.println("onCaptureCompleted for tag = " + request.getTag());

                /*Integer afState = result.get(CaptureResult.CONTROL_AF_STATE);
                Integer aeState = result.get(CaptureResult.CONTROL_AE_STATE);
                
                if (afState != null) {
                    System.out.println("auto focus state was " + getAFStateString(afState) + " in onCaptureCompleted");
                }
                if (aeState != null) {
                    System.out.println("auto exposure state was " + getAEStateString(aeState) + " in onCaptureCompleted");
                }*/

                process(result);
            }
        };

        // Start the background thread for handling the camera callbacks
        startBackgroundThread();

        // Start the camera
        startCamera();
    }

    //////////////////////////
    // Camera setup methods //
    //////////////////////////

    @Override
    public void startCamera() {
        createPreview();
    }

    @Override
    public void releaseCamera() {
        mCameraClosedCallback = "";
        closeCamera();
    }

    // This method opens a new camera
    private void openCamera(SurfaceHolder holder) {

        if (!mCameraView.checkCameraPermissions()) {
            System.err.println("checkCameraPermissions returned false");
            return;
        }

        CameraManager manager = (CameraManager) mContext.getSystemService(CAMERA_SERVICE);
        try {

            // Initialize the camera parameters
            initCamera(holder);

            // Make sure that a lock on the camera opening can be acquired before trying to open the camera
            if (!mCameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) {
                throw new RuntimeException("Time out waiting to lock camera opening.");
            }

            //manager.openCamera(mCameraId, mStateCallback, mBackgroundHandler);
            manager.openCamera(mCameraId, mStateCallback, null);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        } catch (InterruptedException e) {
            throw new RuntimeException("Interrupted while trying to lock camera opening.", e);
        } catch (SecurityException e) {
        }
    }

    // This method closes the current camera
    private void closeCamera() {
        try {
            mCameraOpenCloseLock.acquire();
            if (null != mCaptureSession) {
                mCaptureSession.close();
                mCaptureSession = null;
            }
            if (mCamera != null) {
                mCamera.close();
                mCamera = null;
            }
            if (mJPEGReader != null) {
                mJPEGReader.close();
                mJPEGReader = null;
            }
        } catch (InterruptedException e) {
            throw new RuntimeException("Interrupted while trying to lock camera closing.", e);
        } finally {
            mCameraOpenCloseLock.release();
        }
    }

    // This method initializes the camera preview and adds it to the appropriate layout
    private void createPreview() {

        Log.d(TAG, "createPreview");

        // Reset the mManualAutoFocus flag to its default value
        mManualAutoFocus = false;

        // Setup the outputs for the chosen camera
        try {
            setupCameraOutputs();
        } catch (CameraAccessException cae) {
        }

        // If necessary, create the preview view and set it as the content of the activity.  Set the size of the SurfaceHolder to the chosen preview size
        if (mPreview == null) {
            mPreview = new CameraPreview(mContext);
            mPreview.getHolder().setFixedSize(mPreviewSize.getWidth(), mPreviewSize.getHeight());
            mPreview.getHolder().addCallback(this);
            mCameraView.mPreviewLayout.addView(mPreview);
        } else {

            // TODO: Are the two calls necessary right here?
            // Set the flash mode and resolution mode images
            mCameraView.mCameraLayout.setFlashModeImage(mFlashMode);
            mCameraView.mCameraLayout.setResolutionImage(mResolutionMode);

            // Initialize the camera again by closing the current camera and opening the new one after the onClosed camera state callback has executed
            mCameraClosedCallback = "openCamera";
            closeCamera();
        }
    }

    // This method sets up the camera outputs for the first camera of the chosen type; front- or rear-facing.
    private void setupCameraOutputs() throws CameraAccessException {

        CameraManager cm = (CameraManager) mContext.getSystemService(CAMERA_SERVICE);

        // Get the id of the first camera of the chosen type that has a hardware support level greater than LEGACY
        String[] cameraIDs = cm.getCameraIdList();
        mCameraId = null;
        CameraCharacteristics cc = null;
        for (String id : cameraIDs) {
            cc = cm.getCameraCharacteristics(id);
            int deviceLevel = cc.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
            if (cc.get(CameraCharacteristics.LENS_FACING) == mCameraType
                    && deviceLevel != CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY) {
                mCameraId = id;
                break;
            }
        }
        if (mCameraId == null) {
            throw new CameraAccessException(CameraAccessException.CAMERA_ERROR, "Could not find suitable camera.");
        }

        // Save the camera characteristics for the chosen camera
        mCharacteristics = cc;
        StreamConfigurationMap streamConfigs = mCharacteristics
                .get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP);

        // Double check to make sure the chosen camera can output JPEGs.
        boolean supportsJpeg = false;
        for (int format : streamConfigs.getOutputFormats()) {
            if (format == ImageFormat.JPEG) {
                supportsJpeg = true;
            }
        }
        if (!supportsJpeg) {
            throw new CameraAccessException(CameraAccessException.CAMERA_ERROR,
                    "Could not find supported image format.");
        }

        // Find the largest preview size that will fit the aspect ratio of the preview layout.

        // Get the height and width of the screen in portrait coordinates (where height > width)
        //TODO: I guess this should really be the view size and not the screen size?
        int screenWidth = mCameraView.getWidth(); //CompanyCamApplication.getInstance().getScreenPortraitPixelWidth();
        int screenHeight = mCameraView.getHeight(); //CompanyCamApplication.getInstance().getScreenPortraitPixelHeight();

        // Calculate the aspect ratio of the screen
        double screenAspectRatio = (double) screenHeight / (double) screenWidth;

        // Determine if the screen's aspect ratio is closer to 4x3 or 16x9
        double aspect4x3 = 4.0 / 3.0;
        double aspect16x9 = 16.0 / 9.0;
        Size nearestAspect;
        if (Math.abs(screenAspectRatio - aspect4x3) < Math.abs(screenAspectRatio - aspect16x9)) {
            nearestAspect = new Size(4, 3);
        } else {
            nearestAspect = new Size(16, 9);
        }

        // Choose the optimal preview size based on the available output sizes, the screen size, and the preview layout size.
        mPreviewSize = chooseOptimalSize(streamConfigs.getOutputSizes(SurfaceHolder.class), MAX_PREVIEW_WIDTH,
                MAX_PREVIEW_HEIGHT, nearestAspect);
    }

    // This method initializes the camera object and sets the preview layout size once the mPreviewSurface is ready.
    private void initCamera(SurfaceHolder holder) {
        Log.d(TAG, "initCamera");

        // Initialize the ImageReader with the optimum preview size.
        mPreviewSurface = holder.getSurface();
        setJPEGImageReader(mPreviewSize);

        // Once the preview size is determined, updated the size of mPreview so that the camera view will fill the screen properly.
        configurePreviewLayout();
    }

    // This method configures the size of the mPreviewLayout given the chosen camera preview size
    @Override
    public void configurePreviewLayout() {

        if (mPreview == null) {
            System.out.println("mPreview was null in CCCamera2");
        }

        // Make sure the mPreviewWidth and mPreviewHeight variables are set in the superclass before calling the superclass method.
        // mPreviewSize can't be included in the superclass directly because the Size class wasn't added until API 21.
        mPreviewWidth = mPreviewSize.getWidth();
        mPreviewHeight = mPreviewSize.getHeight();
        super.configurePreviewLayout();
    }

    // This method begins displaying the camera preview after the camera object has been initialized.
    private void initPreview() {

        Log.d(TAG, "initPreview");

        try {

            // Create a CaptureRequest.Builder with the mPreviewSurface
            mPreviewRequestBuilder = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);
            mPreviewRequestBuilder.addTarget(mPreviewSurface);

            // TODO: Is this method call necessary?
            // Set the visibility of the flash button
            mCameraView.mCameraLayout.setFlashButtonVisibility();

            // Create a CameraCaptureSession for the camera preview
            List<Surface> surfaces = Arrays.asList(mPreviewSurface, mJpegCaptureSurface);
            mCamera.createCaptureSession(surfaces, new CameraCaptureSession.StateCallback() {
                @Override
                public void onConfigured(CameraCaptureSession session) {

                    // Make sure the camera hasn't already been closed
                    if (mCamera == null) {
                        return;
                    }

                    // Assign the mCaptureSession variable and update the camera preview
                    mCaptureSession = session;
                    updatePreview();
                }

                @Override
                public void onConfigureFailed(CameraCaptureSession session) {

                }
            }, null);
        } catch (CameraAccessException e) {
            Log.d(TAG, "Failed to create camera capture session", e);
        }
    }

    // Call this whenever some camera control changes (e.g., focus distance, white balance, etc) that should affect the preview
    private void updatePreview() {

        Log.d(TAG, "updatePreview");

        try {
            if (mCamera == null || mCaptureSession == null) {
                Log.d(TAG, "updatePreview camera is null");
                return;
            }

            // TODO: Is this method call necessary?
            // Set the visibility of the flash button
            mCameraView.mCameraLayout.setFlashButtonVisibility();

            // Set a continuous auto focus for the camera preview
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE,
                    CameraMetadata.CONTROL_AF_MODE_CONTINUOUS_PICTURE);

            setFlashModeForRequest(mPreviewRequestBuilder);

            // Set the zoom level for the request
            if (mCurrentZoomLevel != 1.0) {
                Rect zoomRect = getCurrentZoomRect();
                mPreviewRequestBuilder.set(CaptureRequest.SCALER_CROP_REGION, zoomRect);
            }

            // Create the mPreviewRequest
            mPreviewRequestBuilder.setTag(1);
            mPreviewRequest = mPreviewRequestBuilder.build();

            // Start displaying the camera preview
            mCaptureSession.setRepeatingRequest(mPreviewRequest, mCaptureCallback, null);

        } catch (CameraAccessException e) {
            Log.e(TAG, "Failed to start preview.");
        }
    }

    /**
     * Given {@code choices} of {@code Size}s supported by a camera, choose the smallest one that
     * is at least as large as the respective texture view size, and that is at most as large as the
     * respective max size, and whose aspect ratio matches with the specified value. If such size
     * doesn't exist, choose the largest one that is at most as large as the respective max size,
     * and whose aspect ratio matches with the specified value.
     *
     * @param choices           The list of sizes that the camera supports for the intended output
     *                          class
     * @param maxWidth          The maximum width that can be chosen
     * @param maxHeight         The maximum height that can be chosen
     * @param aspectRatio       The aspect ratio
     * @return The optimal {@code Size}, or an arbitrary one if none were big enough
     */
    private Size chooseOptimalSize(Size[] choices, int maxWidth, int maxHeight, Size aspectRatio) {

        // Collect the supported resolutions that are at least as big as the preview Surface
        List<Size> bigEnough = new ArrayList<>();

        // Collect the supported resolutions that are smaller than the preview Surface
        List<Size> notBigEnough = new ArrayList<>();

        // Get the width and height of the reference size that's passed in.
        int w = aspectRatio.getWidth();
        int h = aspectRatio.getHeight();

        // Go through each of the camera's supported preview sizes and compare them to the reference size to find the optimal preview size to use.
        for (Size option : choices) {

            // Check if this preview size is no bigger than the max allowed width and height and that its aspect ratio matches the aspect ratio
            // of the reference size.
            if ((option.getWidth() <= maxWidth) && (option.getHeight() <= maxHeight)
                    && (option.getHeight() * w == option.getWidth() * h)) {

                // Check if the largest dimension of this preview size is at least as large as the minimum requirement for the current
                // resolution selection
                if (Math.max(option.getWidth(),
                        option.getHeight()) >= getDesiredImageHeightForResolution(mResolutionMode)) {
                    bigEnough.add(option);
                } else {
                    notBigEnough.add(option);
                }
            }
        }

        // Pick the smallest preview size of those big enough. If there is none big enough, pick the largest of those not big enough.
        if (bigEnough.size() > 0) {
            return Collections.min(bigEnough, new CCCamera2.CompareSizesByArea());
        } else if (notBigEnough.size() > 0) {
            return Collections.max(notBigEnough, new CCCamera2.CompareSizesByArea());
        } else {
            Log.e(TAG, "Couldn't find any suitable preview size");
            return choices[0];
        }
    }

    // This class compares two Size objects and returns a 1 if the area of the first Size is larger or a -1 if the area of the second Size is larger.
    static class CompareSizesByArea implements Comparator<Size> {

        @Override
        public int compare(Size lhs, Size rhs) {

            // We cast here to ensure the multiplications won't overflow
            return Long.signum((long) lhs.getWidth() * lhs.getHeight() - (long) rhs.getWidth() * rhs.getHeight());
        }
    }

    // This method sets the flash setting to auto flash
    private void setAutoFlash(CaptureRequest.Builder requestBuilder) {
        if (hasFlash()) {
            requestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH);
        }
    }

    // This method sets the flash mode for the given CaptureRequestBuilder
    private void setFlashModeForRequest(CaptureRequest.Builder builder) {
        switch (mFlashMode) {
        case AUTO:
            setAutoFlash(builder);
            break;
        case ON:
            builder.set(CaptureRequest.FLASH_MODE, CameraMetadata.FLASH_MODE_SINGLE);
            break;
        case TORCH:
            builder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
            builder.set(CaptureRequest.FLASH_MODE, CameraMetadata.FLASH_MODE_TORCH);
            break;
        case OFF:
            builder.set(CaptureRequest.FLASH_MODE, CameraMetadata.FLASH_MODE_OFF);
        default:
        }
    }

    // This method sets the proper orientation for the JPEG for the given CaptureRequestBuilder as per the Android documentation
    // https://developer.android.com/reference/android/hardware/camera2/CaptureRequest.html#JPEG_ORIENTATION
    private void setJpegOrientationForRequest(CaptureRequest.Builder builder, int deviceOrientation) {

        if (deviceOrientation == android.view.OrientationEventListener.ORIENTATION_UNKNOWN) {
            return;
        }
        int sensorOrientation = mCharacteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);

        // Round device orientation to a multiple of 90
        deviceOrientation = (deviceOrientation + 45) / 90 * 90;

        // Reverse device orientation for front-facing cameras
        if (mCameraType == CameraCharacteristics.LENS_FACING_FRONT) {
            deviceOrientation = -deviceOrientation;
        }

        // Calculate desired JPEG orientation relative to camera orientation to make the image upright relative to the device orientation
        int jpegOrientation = (sensorOrientation + deviceOrientation + 360) % 360;

        System.out.println("The jpegOrientation is " + jpegOrientation);

        // Set the JPEG orientation
        builder.set(CaptureRequest.JPEG_ORIENTATION, jpegOrientation);
    }

    // This method initiates the mJPEGReader object with the given Size object
    private void setJPEGImageReader(final Size jpegSize) {

        // Initiate the ImageReader object
        Log.d(TAG, "ImageReader getting sized with width = " + jpegSize.getWidth() + " and height = "
                + jpegSize.getHeight());
        mJPEGReader = ImageReader.newInstance(jpegSize.getWidth(), jpegSize.getHeight(), ImageFormat.JPEG, 2);

        // Set the listener for the mJPEGReader
        mJPEGReader.setOnImageAvailableListener(new ImageReader.OnImageAvailableListener() {
            @Override
            public void onImageAvailable(ImageReader reader) {
                Log.d(TAG, "onImageAvailable");
                processPhoto(reader.acquireLatestImage());
            }
        }, null);

        mJpegCaptureSurface = mJPEGReader.getSurface();
    }

    private void capturePhoto() {

        Log.d(TAG, "capturePhoto");

        try {
            CaptureRequest.Builder builder = mCamera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
            builder.set(CaptureRequest.CONTROL_MODE, CameraMetadata.CONTROL_MODE_AUTO);

            // Turn off autofocus while capturing the image
            builder.set(CaptureRequest.CONTROL_AF_MODE, CameraMetadata.CONTROL_AF_MODE_OFF);
            builder.set(CaptureRequest.CONTROL_AF_TRIGGER, CameraMetadata.CONTROL_AF_TRIGGER_IDLE);

            // TODO: set options here that the user has changed

            // Set the flash mode
            setFlashModeForRequest(builder);

            // Set the orientation of the JPEG based on the current camera
            setJpegOrientationForRequest(builder,
                    mCameraView.getActivity().getResources().getConfiguration().orientation);

            // Set the zoom level for the request
            Rect zoomRect = getCurrentZoomRect();
            builder.set(CaptureRequest.SCALER_CROP_REGION, zoomRect);

            builder.set(CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE,
                    CameraMetadata.LENS_OPTICAL_STABILIZATION_MODE_ON);

            builder.addTarget(mJpegCaptureSurface);
            builder.set(CaptureRequest.JPEG_QUALITY, (byte) 100); // TODO: use the user set quality

            mCaptureSession.capture(builder.build(), new CameraCaptureSession.CaptureCallback() {
                @Override
                public void onCaptureStarted(CameraCaptureSession session, CaptureRequest request, long timestamp,
                        long framNumber) {

                }

                @Override
                public void onCaptureCompleted(CameraCaptureSession session, CaptureRequest request,
                        TotalCaptureResult result) {

                    // Play the shutter click sound effect as long as the device ringer is turned on
                    AudioManager mgr = (AudioManager) mContext.getSystemService(Context.AUDIO_SERVICE);
                    switch (mgr.getRingerMode()) {
                    case AudioManager.RINGER_MODE_NORMAL:
                        MediaActionSound sound = new MediaActionSound();
                        sound.play(MediaActionSound.SHUTTER_CLICK);
                        break;
                    default:
                        break;
                    }
                }

                @Override
                public void onCaptureFailed(CameraCaptureSession session, CaptureRequest request,
                        CaptureFailure failure) {
                    super.onCaptureFailed(session, request, failure);
                    Log.e(TAG, "Image capture failed.");
                }
            }, null);

        } catch (CameraAccessException e) {
            Log.e(TAG, "Image capture failed.", e);
        }
    }

    // This method starts a background thread and its handler.
    private void startBackgroundThread() {
        mBackgroundThread = new HandlerThread("CameraBackground");
        mBackgroundThread.start();
        mBackgroundHandler = new Handler(mBackgroundThread.getLooper());
    }

    // This method stops the background thread and its handler.
    private void stopBackgroundThread() {
        mBackgroundThread.quitSafely();
        try {
            mBackgroundThread.join();
            mBackgroundThread = null;
            mBackgroundHandler = null;
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
    }

    ///////////////////////////
    // Zoom handling methods //
    ///////////////////////////

    // This method updates the zoom level for the camera preview given the current motion event
    private void handleZoom(MotionEvent event) {

        // Get the maximum digital zoom level for the current camera
        float maxZoom = (mCharacteristics.get(CameraCharacteristics.SCALER_AVAILABLE_MAX_DIGITAL_ZOOM));

        // Get the finger spacing for this touch event
        double fingerSpacing = getFingerSpacing(event);

        if (fingerSpacing != 0) {

            // Calculate the ratio of the finger spacing at the beginning of this touch event to this finger spacing
            double fingerRatio = mStartingFingerSpacing / fingerSpacing;

            // Calculate a new zoom level that's a multiple of the zoom level at the beginning of this touch event
            double newZoom = mStartingZoomLevel / fingerRatio;

            // Bound the new zoom level by the minimum and maximum zoom levels
            newZoom = Math.min(newZoom, maxZoom);
            newZoom = Math.max(newZoom, 1.0);

            System.out.println(
                    "mStartingFingerSpacing = " + mStartingFingerSpacing + " and fingerSpacing = " + fingerSpacing);
            System.out.println("fingerRatio = " + fingerRatio + " and newZoom = " + newZoom);
            System.out.println(
                    "mStaringZoomLevel = " + mStartingZoomLevel + " and mCurrentZoomLevel = " + mCurrentZoomLevel);

            // Set the new zoom level and update the camera preview
            mCurrentZoomLevel = newZoom;
            updatePreview();
        }
    }

    // This method calculates the zoom rect for the current zoom level and camera
    private Rect getCurrentZoomRect() {
        return getRectForZoomLevel(mCurrentZoomLevel);
    }

    // This method calculates the zoom rect for the given zoom level
    private Rect getRectForZoomLevel(double zoom) {

        // Get the maximum digital zoom level for the current camera
        float minZoom = 1;
        float maxZoom = (mCharacteristics.get(CameraCharacteristics.SCALER_AVAILABLE_MAX_DIGITAL_ZOOM));

        // Get the rect representing the full size of the current camera sensor. This rect is expressed in the camera sensor coordinate system.
        Rect m = mCharacteristics.get(CameraCharacteristics.SENSOR_INFO_ACTIVE_ARRAY_SIZE);

        // Calculate the difference between the minimum and maximum zoom levels
        double delta_z = maxZoom - minZoom;

        // Calculate the width and height of the cropped region at the maximum zoom level
        double w_zmax = m.width() / maxZoom;
        double h_zmax = m.height() / maxZoom;

        // Calculate the delta width and height between the minimum and maximum zoom levels
        double delta_w = m.width() - w_zmax;
        double delta_h = m.height() - h_zmax;

        // Calculate the cropped width and height at the current zoom level
        double w_z = ((minZoom - zoom) / (delta_z)) * delta_w + m.width();
        double h_z = ((minZoom - zoom) / (delta_z)) * delta_h + m.height();

        // Calculate the offset of the cropped region
        int centerX = m.width() / 2;
        int centerY = m.height() / 2;
        int deltaX = (int) (0.5f * w_z);
        int deltaY = (int) (0.5f * h_z);
        int offsetX = centerX - deltaX;
        int offsetY = centerY - deltaY;

        //System.out.println("centerX = " + centerX + ", centerY = " + centerY + ", deltaX = " + deltaX + ", deltaY = " + deltaY);
        //System.out.println("offsetX = " + offsetX + ", offsetY = " + offsetY + ", w_z = " + w_z + ", h_z = " + h_z);

        return new Rect(offsetX, offsetY, centerX + deltaX, centerY + deltaY);

    }

    ////////////////////////////
    // Focus handling methods //
    ////////////////////////////

    // This method handles the auto focus and auto exposure based on the user's touch point
    public void handleFocus(MotionEvent event) {

        LogUtil.e(TAG, "handleFocus was called");

        // Define the size of the FocusIndicatorView as 80dp
        float focusIndicatorSize = TypedValue.applyDimension(TypedValue.COMPLEX_UNIT_DIP, 80,
                mCameraView.getActivity().getResources().getDisplayMetrics());

        // Get the first pointer for this event
        int pointerId = event.getPointerId(0);
        int pointerIndex = event.findPointerIndex(pointerId);

        // Get the pointer's current position
        float x = event.getX(pointerIndex);
        float y = event.getY(pointerIndex);

        // Normalize the touch point coordinates with respect to the height and width of the preview layout
        int previewWidth = mCameraView.mPreviewLayout.getWidth();
        int previewHeight = mCameraView.mPreviewLayout.getHeight();

        // The x and y coordinates from the touch event need to be converted to normalized portrait coordinates for the regionsForNormalizedCoord() method.
        float n_y = y / previewHeight;
        float n_x = x / previewWidth;
        if (mCameraType == CameraMetadata.LENS_FACING_FRONT) {
            n_x = 1.0f - x / previewWidth;
        }

        System.out.println("handleFocus called and n_x = " + n_x + " n_y = " + n_y);
        System.out
                .println("handleFocus called and previewWidth = " + previewWidth + " previewHeight = " + previewHeight);

        // Get the auto focus region for this touch point
        int sensorOrientation = mCharacteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);
        Rect cropRegion = getCurrentZoomRect();
        mMeteringRect = regionsForNormalizedCoord(n_x, n_y, 0.1f, cropRegion, sensorOrientation);

        mPreview.requestLayout();

        // Set the mManualAutoFocus flag and then lock the autofocus
        mManualAutoFocus = true;
        lockFocusToRegion(mMeteringRect);

        // Show the focus indicator view at the x, y position
        mCameraView.mCameraLayout.showAutoFocusIndicator(x, y, mManualAutoFocus);
    }

    /** Compute 3A regions for a sensor-referenced touch coordinate.
     * Returns a MeteringRectangle[] with length 1.
     *
     * @param n_x x coordinate of the touch point, in normalized portrait coordinates.
     * @param n_y y coordinate of the touch point, in normalized portrait coordinates.
     * @param fraction Fraction in [0,1]. Multiplied by min(cropRegion.width(), cropRegion.height())
     *             to determine the side length of the square MeteringRectangle.
     * @param cropRegion Crop region of the image.
     * @param sensorOrientation sensor orientation as defined by
     *             CameraCharacteristics.get(CameraCharacteristics.SENSOR_ORIENTATION).
     */
    private static MeteringRectangle[] regionsForNormalizedCoord(float n_x, float n_y, float fraction,
            final Rect cropRegion, int sensorOrientation) {

        // Calculate half of the side length of the metering square based on the smaller of the cropRegion width or height
        int minCropEdge = Math.min(cropRegion.width(), cropRegion.height());
        int halfSideLength = (int) (0.5f * fraction * minCropEdge);

        // Calculate the output MeteringRectangle in the camera sensor reference frame.
        // n_x, n_y are normalized coordinates in the screen reference frame.
        // The cropRegion is expressed in the camera sensor reference frame.
        // Calculate the point nsc which is (n_x, n_y) expressed in the camera sensor reference frame.
        PointF nsc = convertNormalizedCoords(n_x, n_y, sensorOrientation);

        // Calculate the touch point represented in the camera sensor frame.
        int xCenterSensor = (int) (cropRegion.left + nsc.x * cropRegion.width());
        int yCenterSensor = (int) (cropRegion.top + nsc.y * cropRegion.height());

        // Calculate the metering region that's centered at the touch point and has a side length of 2*halfSideLength
        Rect meteringRegion = new Rect(xCenterSensor - halfSideLength, yCenterSensor - halfSideLength,
                xCenterSensor + halfSideLength, yCenterSensor + halfSideLength);

        // Make sure that the meteringRegion to isn't outside the cropRegion.
        meteringRegion.left = Math.max(meteringRegion.left, cropRegion.left);
        meteringRegion.left = Math.min(meteringRegion.left, cropRegion.right);
        meteringRegion.top = Math.max(meteringRegion.top, cropRegion.top);
        meteringRegion.top = Math.min(meteringRegion.top, cropRegion.bottom);
        meteringRegion.right = Math.max(meteringRegion.right, cropRegion.left);
        meteringRegion.right = Math.min(meteringRegion.right, cropRegion.right);
        meteringRegion.bottom = Math.max(meteringRegion.bottom, cropRegion.top);
        meteringRegion.bottom = Math.min(meteringRegion.bottom, cropRegion.bottom);

        System.out.println("The metering region is " + meteringRegion.toString());

        // Return a new MeteringRectangle array
        return new MeteringRectangle[] { new MeteringRectangle(meteringRegion, 800) };
    }

    // This method locks the focus to a particular metering rectangle based on the user's touch point.  The metering rectangle must be expressed
    // in the current camera's active pixel array reference frame.
    private void lockFocusToRegion(MeteringRectangle[] meteringRect) {

        try {

            mPreviewRequestBuilder.setTag(2);

            // Set the control mode to auto so that the auto focus and auto exposure modes will take effect
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_MODE, CameraMetadata.CONTROL_MODE_AUTO);

            // Set the auto focus regions
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_REGIONS, meteringRect);
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_REGIONS, meteringRect);

            // Set the auto focus mode to auto
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_AUTO);

            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
            mPreviewRequestBuilder.set(CaptureRequest.FLASH_MODE, CameraMetadata.FLASH_MODE_OFF);

            // Start the auto focus
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER, CameraMetadata.CONTROL_AF_TRIGGER_START);

            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CameraMetadata.CONTROL_AE_PRECAPTURE_TRIGGER_START);

            // Start the capture sequence and set the state to STATE_WAITING_LOCK
            mState = STATE_WAITING_LOCK;
            mCaptureSession.stopRepeating();
            mCaptureSession.capture(mPreviewRequestBuilder.build(), mCaptureCallback, mBackgroundHandler);

            // Call update preview to start the preview again
            updatePreview();
        } catch (CameraAccessException e) {
            // error handling
        }
    }

    // This method locks the auto focus as the first step for a still image capture.
    private void lockFocus() {
        try {

            // Set the state in the request builder to initiate the auto focus lock.
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER, CameraMetadata.CONTROL_AF_TRIGGER_START);

            // Update the camera state to indicate that the preview is waiting for the auto focus to lock
            mState = STATE_WAITING_LOCK;

            // Use the mCaptureSession to initiate the auto focus lock
            mCaptureSession.capture(mPreviewRequestBuilder.build(), mCaptureCallback, null);

        } catch (CameraAccessException e) {
            e.printStackTrace();
        }
    }

    // This method unlocks the auto focus when the still image capture sequence is finished.
    private void unlockFocus() {
        try {

            System.out.println("unlockFocus called");

            // Make sure this runs on the main thread since it updates the UI.  Sometimes this method gets called from a background thread.
            mCameraView.post(new Runnable() {
                @Override
                public void run() {
                    mCameraView.mCameraLayout.hideAutoFocusIndicator();
                }
            });

            // Reset the auto focus trigger
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_TRIGGER, CameraMetadata.CONTROL_AF_TRIGGER_CANCEL);
            setAutoFlash(mPreviewRequestBuilder);

            // Reset the auto exposure trigger
            if (android.os.Build.VERSION.SDK_INT >= 23) {
                mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                        CameraMetadata.CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL);
            }

            // Set the camera state back to the default preview state
            mState = STATE_PREVIEW;

            // Start the preview again
            if (mCaptureSession != null) {
                mCaptureSession.capture(mPreviewRequestBuilder.build(), mCaptureCallback, null);
                mCaptureSession.setRepeatingRequest(mPreviewRequest, mCaptureCallback, null);
            }
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }
    }

    ///////////////////////////
    // Photo capture methods //
    ///////////////////////////

    // This method initiates a still image capture by calling the lockFocus() method to lock the auto focus.
    private void initiatePhotoCapture() {

        // Set this flag to true to bypass the full AF and AE routine for capturing a photo in basic Camera mode.
        boolean bypassAutoFocus = (mFlashMode == FlashMode.OFF) || (mFlashMode == FlashMode.TORCH);

        // If the camera is in FastCam mode, then capture the photo immediately without going through the auto focus and auto exposure.
        if ((mCameraMode == CameraMode.FASTCAM) || bypassAutoFocus) {
            captureStillPicture();
        }

        // Otherwise, try to lock the focus before capturing the photo
        else {
            lockFocus();
        }
    }

    // This method runs the precapture sequence for capturing a still image. It starts the auto exposure.
    // This method should be called when the mCaptureCallback gets a response from lockFocus().
    private void runPrecaptureSequence() {
        try {

            System.out.println("runPrecaptureSequence was called");

            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AF_MODE,
                    CameraMetadata.CONTROL_AF_MODE_CONTINUOUS_PICTURE);

            // Set the states in the request builder to initiate the auto exposure.
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON);
            mPreviewRequestBuilder.set(CaptureRequest.FLASH_MODE, CameraMetadata.FLASH_MODE_OFF);
            mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER,
                    CaptureRequest.CONTROL_AE_PRECAPTURE_TRIGGER_START);

            // Add the metering region to the request if the mManualAutoFocus flag is set
            if (mManualAutoFocus) {
                mPreviewRequestBuilder.set(CaptureRequest.CONTROL_AE_REGIONS, mMeteringRect);
            }

            // Update the camera state to indicate that the preview is waiting for the auto exposure to finish
            mState = STATE_WAITING_PRECAPTURE;

            // Use the mCaptureSession to initiate the auto exposure
            mCaptureSession.capture(mPreviewRequestBuilder.build(), mCaptureCallback, null);

        } catch (CameraAccessException e) {
            e.printStackTrace();
        }
    }

    // This method captures a still picture. This method should be called when we get a response in the mCaptureCallback from both
    // lockFocus() and runPrecaptureSequence().
    private void captureStillPicture() {
        System.out.println("captureStillPicture was called");

        try {
            if (mCamera == null) {
                return;
            }

            // Create a CaptureRequest.Builder to use to take the photo.
            final CaptureRequest.Builder captureBuilder = mCamera
                    .createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE);
            captureBuilder.addTarget(mJpegCaptureSurface);

            // Use the same auto exposure and auto focus modes as the preview.
            captureBuilder.set(CaptureRequest.CONTROL_AF_MODE, CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);

            // Set the flash mode for the request
            setFlashModeForRequest(captureBuilder);

            // Set the zoom level for the request
            Rect zoomRect = getCurrentZoomRect();
            captureBuilder.set(CaptureRequest.SCALER_CROP_REGION, zoomRect);
            captureBuilder.set(CaptureRequest.LENS_OPTICAL_STABILIZATION_MODE,
                    CameraMetadata.LENS_OPTICAL_STABILIZATION_MODE_ON);

            // Set the orientation for the JPEG
            int rotation = mCameraView.getActivity().getWindowManager().getDefaultDisplay().getRotation();
            captureBuilder.set(CaptureRequest.JPEG_ORIENTATION, getOrientation(rotation));

            CameraCaptureSession.CaptureCallback CaptureCallback = new CameraCaptureSession.CaptureCallback() {

                @Override
                public void onCaptureCompleted(@NonNull CameraCaptureSession session, @NonNull CaptureRequest request,
                        @NonNull TotalCaptureResult result) {

                    // Play the shutter click sound effect as long as the device ringer is turned on
                    AudioManager mgr = (AudioManager) mContext.getSystemService(Context.AUDIO_SERVICE);
                    switch (mgr.getRingerMode()) {
                    case AudioManager.RINGER_MODE_NORMAL:
                        MediaActionSound sound = new MediaActionSound();
                        sound.play(MediaActionSound.SHUTTER_CLICK);
                        break;
                    default:
                        break;
                    }

                    // Animate the screen flash when the image is captured if the camera is in FastCam mode.
                    mCameraView.post(new Runnable() {
                        @Override
                        public void run() {
                            mCameraView.mCameraLayout.animateScreenFlash();
                        }
                    });

                    // Unlock the auto focus again after the photo is taken
                    unlockFocus();
                }
            };

            mCaptureSession.stopRepeating();
            mCaptureSession.capture(captureBuilder.build(), CaptureCallback, null);
        } catch (CameraAccessException e) {
            e.printStackTrace();
        }
    }

    /**
     * Retrieves the JPEG orientation from the specified screen rotation.
     *
     * @param rotation The screen rotation.
     * @return The JPEG orientation (one of 0, 90, 270, and 360)
     */
    private int getOrientation(int rotation) {
        // Sensor orientation is 90 for most devices, or 270 for some devices (eg. Nexus 5X)
        // We have to take that into account and rotate JPEG properly.
        // For devices with orientation of 90, we simply return our mapping from ORIENTATIONS.
        // For devices with orientation of 270, we need to rotate the JPEG 180 degrees.
        int sensorOrientation = mCharacteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);
        System.out
                .println("in getOrientation rotation = " + rotation + " and sensorOrientation = " + sensorOrientation);

        // Per the Google example project Camera2Basic, the angle at which the JPEG needs to be rotated is a function of the device orientation
        // and the sensor orientation + 270.  However, implementing this resulted in images being upside down for any sensors that have an
        // orientation of 270.  Simply using the value from the ORIENTATIONS array has resulted in correct captured image orientations on all
        // tested devices so far because the images are rotated manually after the JPEG is captured before it's stored in the file system.
        //return (ORIENTATIONS.get(rotation) + sensorOrientation + 270) % 360;
        return (ORIENTATIONS.get(rotation));
    }

    ///////////////////////////
    // Process Photo methods //
    ///////////////////////////

    private void processPhoto(Image image) {
        Log.d(TAG, "processPhoto()");

        ByteBuffer buffer = image.getPlanes()[0].getBuffer();
        byte[] data = new byte[buffer.capacity()];
        buffer.get(data);

        image.close();

        Log.d(TAG, "byte[] data created");

        if (data != null) {
            Bitmap bPhoto = null;
            try {

                BitmapFactory.Options options = new BitmapFactory.Options();

                // Decoding the data with inJustDecodeBounds = true returns a null bitmap, but it decodes the size without having to
                // allocate memory for all the pixels.
                //options.inJustDecodeBounds = true;
                //BitmapFactory.decodeByteArray(data, 0, data.length, options);

                // Decode bitmap with inSampleSize set
                options.inJustDecodeBounds = false;

                // Get the bitmap (options will resize it if set)
                bPhoto = BitmapFactory.decodeByteArray(data, 0, data.length, options);

                Log.d(TAG, "Bitmap bPhoto decoded from data.");

                // The attempt to decode the data can sometimes fail and return null.  If that happens, display a message to the user and restart the camera preview..
                if (bPhoto == null) {

                    new AlertDialog.Builder(mContext).setTitle("Error").setMessage(
                            "Something went wrong while taking this photo. Try taking a picture with your camera app and uploading it.")
                            .setNeutralButton(R.string.ok, new DialogInterface.OnClickListener() {
                                @Override
                                public void onClick(DialogInterface dialog, int which) {
                                    // TODO: restart the camera somehow
                                    dialog.dismiss();
                                }
                            }).create().show();

                    return;
                }

                int orientation = ((mLastOrientation + 45) / 90) * 90;

                // Reverse device orientation for front-facing cameras
                if (mCameraType == CameraCharacteristics.LENS_FACING_FRONT) {
                    orientation = -orientation;
                }

                // Calculate the rotation angle to apply to the image
                int rotation = 0;
                int cameraOrientation = mCharacteristics.get(CameraCharacteristics.SENSOR_ORIENTATION);
                rotation = (cameraOrientation + orientation) % 360;

                // Create the transformation matrix for the image
                Matrix matrix = new Matrix();
                Log.d(TAG, "before getWidth()");
                int theW = bPhoto.getWidth();
                Log.d(TAG, "after getWidth()");
                Log.d(TAG, "before getHeight()");
                int theH = bPhoto.getHeight();
                Log.d(TAG, "after getHeight()");

                // Mirror the image for the front-facing camera
                if (mCameraType == CameraCharacteristics.LENS_FACING_FRONT) {
                    matrix.setScale(1, -1);
                    matrix.postTranslate(0, theH);

                    if (theH > theW) {
                        rotation = (rotation - 270) % 360;
                    }
                } else if (theH > theW) {
                    rotation = (rotation - 90) % 360;
                }

                // Rotate the image according to the sensor and device orientations
                matrix.postRotate(rotation);

                Log.d(TAG, "calculations done, ready to rotate");
                bPhoto = Bitmap.createBitmap(bPhoto, 0, 0, theW, theH, matrix, false); // This is slow ~3 seconds

                Log.d(TAG, "Before cropping the photo is " + bPhoto.getWidth() + " x " + bPhoto.getHeight());

                // Get the height and width of the screen in portrait coordinates (where height > width)
                //TODO: I guess this should really be the view size and not the screen size?
                double screenWidth = (double) mCameraView.getWidth(); //CompanyCamApplication.getInstance().getScreenPortraitPixelWidth();
                double screenHeight = (double) mCameraView.getHeight(); //CompanyCamApplication.getInstance().getScreenPortraitPixelHeight();

                // Crop the image to the screen aspect ratio
                bPhoto = PhotoUtils.cropBitmapToScreen(bPhoto, screenWidth, screenHeight);

                Log.d(TAG, "After cropping the photo is " + bPhoto.getWidth() + " x " + bPhoto.getHeight());

                Log.d(TAG, "bPhoto rotated and ready for storage.");

                File photo = getPhotoPath();
                if (photo.exists()) {
                    photo.delete();
                }

                FileOutputStream out = new FileOutputStream(photo.getPath());
                BufferedOutputStream bos = new BufferedOutputStream(out);
                bPhoto.compress(Bitmap.CompressFormat.JPEG, HIGH_QUALITY, bos);
                int imgWidth = bPhoto.getWidth();
                int imgHeight = bPhoto.getHeight();

                bos.flush();
                bos.close();
                out.close();

                Log.d(TAG, "bPhoto saved to mFile");

                //TODO: better if gotoEdit/uploadFastCam are done *after* exif is set and bPhoto is recycled?
                // If the current mode is FastCam, then upload the photo immediately
                if (mCameraMode == CameraMode.FASTCAM) {
                    uploadFastCamPhoto(photo, imgWidth, imgHeight, PhotoOrigin.fromCameraMode(mCameraMode));
                }
                // Transition to the EditPhotoCaptureActivity as long as the current mode isn't FastCam
                else {
                    gotoEditPhotoCapture(photo.getPath(), imgWidth, imgHeight, PhotoOrigin.fromCameraMode(mCameraMode));
                }

                try {
                    ExifUtils.setAttributes(photo, mCameraView.getExifLocation(), mFlashMode);
                } catch (IOException e) {
                    LogUtil.e(TAG, e.getLocalizedMessage());
                }

            } catch (FileNotFoundException e) {
                Log.d(TAG, "File not found: " + e.getMessage());
            } catch (IOException e) {
                Log.d(TAG, "Error accessing file: " + e.getMessage());
            } catch (OutOfMemoryError oome) {
                Log.e(TAG, "OutOfMemoryError: " + oome.getMessage());
                mCameraView.finishWithError("Out of memory: " + oome.getMessage());
            } finally {
                if (bPhoto != null) {
                    bPhoto.recycle();
                    bPhoto = null;
                }
            }
        }
    }

    ///////////////////////////////
    // CCCameraInterface methods //
    ///////////////////////////////

    @Override
    public void setResolution(ResolutionMode mode) {

        if (mCamera != null) {

            // Initialize the camera again
            //createPreview();

            try {
                setupCameraOutputs();
                initCamera(mPreview.getHolder());
                initPreview();
            } catch (CameraAccessException cae) {
            }

        }
    }

    @Override
    public boolean hasFrontCamera() {

        // Check if this device contains a front-facing camera
        boolean foundFrontCamera = false;
        try {
            CameraManager cm = (CameraManager) mContext.getSystemService(CAMERA_SERVICE);
            String[] cameraIDs = cm.getCameraIdList();
            for (String id : cameraIDs) {
                CameraCharacteristics cc = cm.getCameraCharacteristics(id);
                int deviceLevel = cc.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
                if (cc.get(CameraCharacteristics.LENS_FACING) == CameraCharacteristics.LENS_FACING_FRONT
                        && deviceLevel != CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY) {
                    foundFrontCamera = true;
                }
            }
        } catch (CameraAccessException cae) {
        }

        return foundFrontCamera;
    }

    @Override
    public boolean hasRearCamera() {

        // Check if this device contains a rear-facing camera
        boolean foundRearCamera = false;
        try {
            CameraManager cm = (CameraManager) mContext.getSystemService(CAMERA_SERVICE);
            String[] cameraIDs = cm.getCameraIdList();
            for (String id : cameraIDs) {
                CameraCharacteristics cc = cm.getCameraCharacteristics(id);
                int deviceLevel = cc.get(CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL);
                if (cc.get(CameraCharacteristics.LENS_FACING) == CameraCharacteristics.LENS_FACING_BACK
                        && deviceLevel != CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_LEGACY) {
                    foundRearCamera = true;
                }
            }
        } catch (CameraAccessException cae) {
        }

        return foundRearCamera;
    }

    @Override
    public void toggleCamera() {

        if (mCameraType == CameraCharacteristics.LENS_FACING_BACK) {
            mCameraType = CameraCharacteristics.LENS_FACING_FRONT;
        } else {
            mCameraType = CameraCharacteristics.LENS_FACING_BACK;
        }

        // Reset the mCurrentZoomLevel and the mStartingFingerSpacing
        mCurrentZoomLevel = 1.0;
        mStartingFingerSpacing = -1.0;

        // Initialize the camera again
        createPreview();
    }

    @Override
    public boolean hasFlash() {
        if (mCamera == null) {
            return false;
        }

        return mCharacteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE);
    }

    @Override
    public void toggleFlash() {
        if (mFlashMode == FlashMode.TORCH) {
            setFlash(FlashMode.OFF);
        } else {
            setFlash(FlashMode.TORCH);
        }
    }

    @Override
    public void setFlash(FlashMode mode) {
        mFlashMode = mode;

        // Call updatePreview to get the light to turn on or off if necessary
        updatePreview();
    }

    @Override
    public void takePicture() {

        if (mCamera != null) {
            try {
                initiatePhotoCapture();
            } catch (RuntimeException re) {
                Log.e(TAG, "RuntimeEx takePicture" + re.getMessage());
            }
        }
    }

    @Override
    public boolean handleTouchEvent(MotionEvent event) {

        // If the camera is null, then return
        if (mCamera == null) {
            LogUtil.e(TAG, "The camera instance was null when the screen was touched.");
            return false;
        }

        // Handle the touch event as long as the camera isn't null
        if (mCamera != null) {

            final int action = event.getAction();

            // Handle multi-touch events
            if (action == MotionEvent.ACTION_POINTER_DOWN) {

            }
            if (action == MotionEvent.ACTION_DOWN) {

            } else if (action == MotionEvent.ACTION_MOVE) {

                // Check if this is a multi-touch event
                if (event.getPointerCount() > 1) {

                    // Set the mMultiTouchDetected flag
                    mMultiTouchDetected = true;

                    // Record the initial finger spacing and zoom level if necessary
                    if (mStartingFingerSpacing == -1.0) {
                        mStartingFingerSpacing = getFingerSpacing(event);
                        mStartingZoomLevel = mCurrentZoomLevel;
                    }

                    // Handle the zoom event and update the preview
                    handleZoom(event);
                }
            }

            else if (action == MotionEvent.ACTION_UP) {

                // Trigger the tap-to-autofocus if this was a single tap
                if (event.getPointerCount() == 1 && !mMultiTouchDetected) {
                    handleFocus(event);
                } else {

                    // Reset the mMultiTouchDetected flag
                    mMultiTouchDetected = false;
                }

                // Reset the mStartingFingerSpacing
                mStartingFingerSpacing = -1.0;
            }
        } else {
            LogUtil.e(TAG, "Unable to retrieve camera instance in the touch listener.");
            return false;
        }

        return true;
    }

    ///////////////////////////////////
    // SurfaceHolderCallback methods //
    ///////////////////////////////////

    @Override
    public void surfaceCreated(SurfaceHolder holder) {

        Log.d(TAG, "surfaceCreated");

        if (mCaptureSession != null) {
            mCaptureSession.close();
        }

        // Set the SurfaceCreated flag
        mPreview.mSurfaceCreated = true;

        // The Surface has been created, now initialize the camera

        // Set the flash mode and resolution mode images
        mCameraView.mCameraLayout.setFlashModeImage(mFlashMode);
        mCameraView.mCameraLayout.setResolutionImage(mResolutionMode);

        // Initialize the camera
        openCamera(holder);
    }

    @Override
    public void surfaceDestroyed(SurfaceHolder holder) {

        Log.d(TAG, "surfaceDestroyed");

        // Set the mSurfaceCreated flag
        mPreview.mSurfaceCreated = false;
        if (mCaptureSession != null) {
            mCaptureSession.close();
        }

        LogUtil.e(TAG, "surfaceDestroyed was called");

        if (mCamera != null) {
            mCameraClosedCallback = "";
            closeCamera();
            LogUtil.e(TAG, "The camera was released");
        }
    }

    @Override
    public void surfaceChanged(SurfaceHolder holder, int format, int w, int h) {

        Log.d(TAG, "surfaceChanged width = " + w + " and height = " + h);

        // If your preview can change or rotate, take care of those events here.
        // Make sure to stop the preview before resizing or reformatting it.

        if (mPreview.getHolder().getSurface() == null) {

            Log.d(TAG, "the surface was null in surfaceChanged");
            // preview surface flaes not exist
            return;
        }

        // set preview size and make any resize, rotate or reformatting changes here

        // start preview with new settings
        //createPreview();
    }

    // This is a helper method for logging the auto focus state
    private static String getAFStateString(int afState) {
        switch (afState) {
        case 0:
            return "CONTROL_AF_STATE_INACTIVE";
        case 1:
            return "CONTROL_AF_STATE_PASSIVE_SCAN";
        case 2:
            return "CONTROL_AF_STATE_PASSIVE_FOCUSED";
        case 3:
            return "CONTROL_AF_STATE_ACTIVE_SCAN";
        case 4:
            return "CONTROL_AF_STATE_FOCUSED_LOCKED";
        case 5:
            return "CONTROL_AF_STATE_NOT_FOCUSED_LOCKED";
        case 6:
            return "CONTROL_AF_STATE_PASSIVE_UNFOCUSED";
        default:
            return "Unknown";
        }
    }

    // This is a helper method for logging the auto exposure state
    private static String getAEStateString(int aeState) {
        switch (aeState) {
        case 0:
            return "CONTROL_AE_STATE_INACTIVE";
        case 1:
            return "CONTROL_AE_STATE_SEARCHING";
        case 2:
            return "CONTROL_AE_STATE_CONVERGED";
        case 3:
            return "CONTROL_AE_STATE_LOCKED";
        case 4:
            return "CONTROL_AE_STATE_FLASH_REQUIRED";
        case 5:
            return "CONTROL_AE_STATE_PRECAPTURE";
        default:
            return "Unknown";
        }
    }
}
